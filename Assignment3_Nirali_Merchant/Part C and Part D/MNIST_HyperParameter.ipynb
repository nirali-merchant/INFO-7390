{"cells":[{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["import tensorflow as tf\nimport matplotlib.pyplot as plt\n%matplotlib inline"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["from tensorflow.examples.tutorials.mnist import input_data"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["from time import time"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["tick = time()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["mnist  = input_data.read_data_sets(\"/tmp/data\",one_hot =True)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["type(mnist)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["mnist.train.images.shape"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["sample  = mnist.train.images[2].reshape(28,28)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["plt.imshow(sample,cmap ='Greys')"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["batch_size = 100\nn_classes = 10\nn_samples = mnist.train.num_examples\nn_input  = 784\nn_output =10"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["def multilayer_perceptron(x,weights,biases):\n    \n    '''\n    x:Placeholder for data input\n    weights : dictionary for weights\n    biases : dict of bias values\n    '''\n    #First hidden Layer activation RELU activation \n    #x*w + bias\n    layer_1 = tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n    # RELU(x*w+bias) -> f(x) = max(0,x)\n    layer_1 = tf.nn.relu(layer_1) \n    \n    \n    #Second hidden layer\n    layer_2 = tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n    layer_2 = tf.nn.relu(layer_2) \n    \n    #Output layer\n    out_layer = tf.matmul(layer_2,weights['out']) + biases['out']\n    \n    return out_layer"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["sess = tf.InteractiveSession()"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["def model(training_epochs,l,n_hidden_1,n_hidden_2):\n        \n        weights= {\n    'h1': tf.Variable(tf.random_normal([n_input,n_hidden_1])),\n    'h2': tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2])),\n    'out': tf.Variable(tf.random_normal([n_hidden_2,n_classes]))\n        }\n        \n        biases= {\n    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n    'out': tf.Variable(tf.random_normal([n_classes]))\n        }\n        x = tf.placeholder('float',[None,n_input])\n        y = tf.placeholder('float',[None, n_classes])\n        pred = multilayer_perceptron(x,weights,biases)\n        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( logits=pred, labels=y))\n        optimizer = tf.train.AdamOptimizer(learning_rate=l).minimize(cost)\n        #initializing variables\n        init = tf.initialize_all_variables()\n        sess.run(init)\n        learning_rate = l\n        for epoch in range(training_epochs):\n                #cost\n            avg_cost= 0.0\n\n            total_batch = int(n_samples/batch_size) #55000/100 batches total\n\n            for i in range(total_batch):\n\n                batch_x,batch_y = mnist.train.next_batch(batch_size)\n\n                _,c = sess.run([optimizer,cost],feed_dict={x:batch_x,y:batch_y})\n\n                avg_cost += c/total_batch\n\n            print(\"Epoch : {}  cost{:4f}\".format(epoch+1,avg_cost ) ) \n\n        print(\"Model has completed {} epochs of training\".format(training_epochs))\n        correct_predictions = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n        correct_predictions = tf.cast(correct_predictions,'float')\n        accuracy = tf.reduce_mean(correct_predictions)\n        acc = accuracy.eval({x:mnist.test.images,y:mnist.test.labels})\n        error = 1 - acc\n        print(\"**********************************\")\n        print(\"Accuracy : {}\".format(acc))    \n        print(\"Error : {}\".format(error))\n        print(\"**********************************\")\n        return error"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["t = mnist.train.next_batch(1)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["Xsamp , ysamp = t"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["plt.imshow(Xsamp.reshape(28,28),cmap='Greys')"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["ysamp"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["import numpy as np\nimport pandas as pd\ndf = pd.DataFrame(columns=['learning_rate','hidden_layer_neurons','error'])\nlearning_rates = np.array([0.001,0.005,0.01,0.05,0.1])\nhidden_count = np.array([64, 128, 256, 512, 1024])\nfor i in learning_rates:\n    print(\"Learning rate : {} \".format(i))\n    print(\"----------------------------------------------------------\")\n    print(\"----------------------------------------------------------\")    \n    for j in hidden_count:\n        print(\"Number of neurons in hidden layers : {} \".format(j))\n        print(\"_____________________________________________________________\")\n        error = model(5,i,j,j)\n        df = df.append({'learning_rate': i,'hidden_layer_neurons':j,'error':error}, ignore_index=True)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["df"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["df[df.error<0.2].pivot(index='learning_rate',columns='hidden_layer_neurons',values='error').plot()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["mnist.test.labels"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["mnist.test.images"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["tock = time()\nprint(tock - tick)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":29}],"metadata":{"name":"MNIST_HyperParameter","notebookId":3867599883139002},"nbformat":4,"nbformat_minor":0}
